---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: logging
data:
  fluent.conf: |-
     @include systemd.conf
     @include prometheus.conf
     @include kubernetes.conf
     @include conf.d/*.conf

     # Used for health checking
     <source>
       @type http
       port 9880
       bind 0.0.0.0
     </source>

     # promethus additional outgoing and incoming counts
     # count number of incoming records per tag
     <filter **>
        @type prometheus
        <metric>
         name fluentd_input_status_num_records_total
         type counter
         desc The total number of incoming records
         <labels>
          tag ${tag}
          hostname ${hostname}
         </labels>
        </metric>
     </filter>

     <filter **>
      @type record_transformer
      <record>
        cluster "#{ENV['CLUSTER']}"
      </record>
     </filter>

     <match **>
       @type copy
       <store>
         @type prometheus
         <metric>
           name fluentd_output_status_num_records_total
           type counter
           desc The total number of outgoing records
           <labels>
             tag ${tag}
             hostname ${hostname}
           </labels>
         </metric>
       </store>
       <store>
         @type kafka_buffered
         @id out_kafka
         brokers "#{ENV['FLUENT_KAFKA_BROKERS']}"
         default_topic "#{ENV['FLUENT_KAFKA_DEFAULT_TOPIC'] || nil}"
         output_data_type "json"
         output_include_tag false
         output_include_time false
         exclude_topic_key false
         exclude_partition_key false
         get_kafka_client_log true
         max_send_retries 2
         required_acks 1
         ack_timeout ""
         discard_kafka_delivery_failed false
         <buffer>
           flush_mode interval
           flush_interval 10s
           flush_thread_count 8
           total_limit_size {{ fluentd_buffer_total_size | default("10G")  }}
           @type "file"
           path "/data"
           retry_type exponential_backoff
         </buffer>
       </store>
     </match>

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config-kube
  namespace: logging
data:
  kubernetes.conf: |-
     # Override conf in image with this file
     <match kubernetes.var.log.containers.fluentd**>
       @type null
     </match>

     <match fluent.**>
       @type null
     </match>
     
     <source>
       @type tail
       @id in_tail_container_logs
       path /var/log/containers/*.log
       exclude_path ["/var/log/containers/kafka*", "/var/log/containers/fluentd*"]
       pos_file /var/log/fluentd-containers.log.pos
       tag raw.kubernetes.*
       read_from_head true
       <parse>
         @type "#{ENV['FLUENT_CONTAINER_TAIL_PARSER_TYPE'] || 'json'}"
         time_key time
         keep_time_key true
         time_format %Y-%m-%dT%H:%M:%S.%NZ
       </parse>
     </source>
     
     # Detect exceptions in the log output and forward them as one log entry.
     <match raw.kubernetes.**>
       @id raw.kubernetes
       @type detect_exceptions
       remove_tag_prefix raw
       message log
       stream stream
       multiline_flush_interval 5
       max_bytes 500000
       max_lines 1000
     </match>
     
     # Concatenate multi-line logs
     <filter **>
       @id filter_concat
       @type concat
       key message 
       multiline_end_regexp /\n$/
       separator ""
     </filter>
     
     <source>
       @type tail
       @id in_tail_startupscript
       path /var/log/startupscript.log
       pos_file /var/log/fluentd-startupscript.log.pos
       tag startupscript
       <parse>
         time_key time
         keep_time_key true
         @type syslog
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_docker
       path /var/log/docker.log
       pos_file /var/log/fluentd-docker.log.pos
       tag docker
       <parse>
         @type regexp
         time_key time
         keep_time_key true
         expression /^time="(?<time>[^)]*)" level=(?<severity>[^ ]*) msg="(?<message>[^"]*)"( err="(?<error>[^"]*)")?( statusCode=($<status_code>\d+))?/
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_etcd
       path /var/log/etcd.log
       pos_file /var/log/fluentd-etcd.log.pos
       tag etcd
       <parse>
         @type none
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_kubelet
       multiline_flush_interval 5s
       path /var/log/kubelet.log
       pos_file /var/log/fluentd-kubelet.log.pos
       tag kubelet
       <parse>
         @type multiline_kubernetes
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_kube_proxy
       multiline_flush_interval 5s
       path /var/log/kube-proxy.log
       pos_file /var/log/fluentd-kube-proxy.log.pos
       tag kube-proxy
       <parse>
         @type multiline_kubernetes
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_kube_apiserver
       multiline_flush_interval 5s
       path /var/log/kube-apiserver.log
       pos_file /var/log/fluentd-kube-apiserver.log.pos
       tag kube-apiserver
       <parse>
         @type multiline_kubernetes
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_kube_controller_manager
       multiline_flush_interval 5s
       path /var/log/kube-controller-manager.log
       pos_file /var/log/fluentd-kube-controller-manager.log.pos
       tag kube-controller-manager
       <parse>
         @type multiline_kubernetes
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_kube_scheduler
       multiline_flush_interval 5s
       path /var/log/kube-scheduler.log
       pos_file /var/log/fluentd-kube-scheduler.log.pos
       tag kube-scheduler
       <parse>
         @type multiline_kubernetes
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_rescheduler
       multiline_flush_interval 5s
       path /var/log/rescheduler.log
       pos_file /var/log/fluentd-rescheduler.log.pos
       tag rescheduler
       <parse>
         @type multiline_kubernetes
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_glbc
       multiline_flush_interval 5s
       path /var/log/glbc.log
       pos_file /var/log/fluentd-glbc.log.pos
       tag glbc
       <parse>
         @type multiline_kubernetes
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     <source>
       @type tail
       @id in_tail_cluster_autoscaler
       multiline_flush_interval 5s
       path /var/log/cluster-autoscaler.log
       pos_file /var/log/fluentd-cluster-autoscaler.log.pos
       tag cluster-autoscaler
       <parse>
         @type multiline_kubernetes 
         time_key time
         keep_time_key true
       </parse>
     </source>
     
     # Example:
     # 2017-02-09T00:15:57.992775796Z AUDIT: id="90c73c7c-97d6-4b65-9461-f94606ff825f" ip="104.132.1.72" method="GET" user="kubecfg" as="<self>" asgroups="<lookup>" namespace="default" uri="/api/v1/namespaces/default/pods"
     # 2017-02-09T00:15:57.993528822Z AUDIT: id="90c73c7c-97d6-4b65-9461-f94606ff825f" response="200"
     <source>
       @type tail
       @id in_tail_kube_apiserver_audit
       multiline_flush_interval 5s
       path /var/log/kubernetes/kube-apiserver-audit.log
       pos_file /var/log/kube-apiserver-audit.log.pos
       tag kube-apiserver-audit
       <parse>
         @type multiline
         format_firstline /^\S+\s+AUDIT:/
         # Fields must be explicitly captured by name to be parsed into the record.
         # Fields may not always be present, and order may change, so this just looks
         # for a list of key="\"quoted\" value" pairs separated by spaces.
         # Unknown fields are ignored.
         # Note: We can't separate query/response lines as format1/format2 because
         #       they don't always come one after the other for a given query.
         format1 /^(?<time>\S+) AUDIT:(?: (?:id="(?<id>(?:[^"\\]|\\.)*)"|ip="(?<ip>(?:[^"\\]|\\.)*)"|method="(?<method>(?:[^"\\]|\\.)*)"|user="(?<user>(?:[^"\\]|\\.)*)"|groups="(?<groups>(?:[^"\\]|\\.)*)"|as="(?<as>(?:[^"\\]|\\.)*)"|asgroups="(?<asgroups>(?:[^"\\]|\\.)*)"|namespace="(?<namespace>(?:[^"\\]|\\.)*)"|uri="(?<uri>(?:[^"\\]|\\.)*)"|response="(?<response>(?:[^"\\]|\\.)*)"|\w+="(?:[^"\\]|\\.)*"))*/
         time_format %Y-%m-%dT%T.%L%Z
       </parse>
     </source>
     
     <filter kubernetes.**>
       @type kubernetes_metadata
       @id filter_kube_metadata
     </filter>
     


